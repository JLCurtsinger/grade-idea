name: Ping Search Engines

on:
  push:
    branches: [ "main" ]

jobs:
  ping:
    runs-on: ubuntu-latest
    env:
      STRICT_SEO: false
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install deps
        run: npm ci

      # Wait up to ~5 minutes for Vercel's auto-deploy to go live
      - name: Wait for site to be live
        run: |
          URL="https://www.gradeidea.cc/sitemap.xml"
          for i in {1..60}; do
            code=$(curl -s -o /dev/null -w "%{http_code}" "$URL")
            echo "Attempt $i: $code"
            if [ "$code" = "200" ]; then
              exit 0
            fi
            sleep 5
          done
          echo "Site not live yet (sitemap still not 200)."
          exit 1

      - name: Validate sitemap like Googlebot (verbose)
        run: |
          set -x
          URL="https://www.gradeidea.cc/sitemap.xml"
          echo "=== HEAD ==="; curl -sI "$URL" || true
          echo "=== GET as Googlebot ==="
          curl -v -A "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" \
            -o /tmp/sm.xml -w "\nHTTP:%{http_code}\n" "$URL" || true
          echo "=== file -bi ==="
          file -bi /tmp/sm.xml || true
          echo "=== first 20 lines ==="
          sed -n '1,20p' /tmp/sm.xml || true
          ct=$(file -bi /tmp/sm.xml || echo "")
          if echo "$ct" | grep -qi xml; then
            echo "Looks like XML."
          else
            echo "::warning::Sitemap does not look like XML (Content-Type=$ct)"
            [ "${STRICT_SEO}" = "true" ] && exit 1 || true
          fi

      - name: Quick XML well-formedness check (xmllint)
        run: |
          set -x
          sudo apt-get update -y && sudo apt-get install -y libxml2-utils
          if ! xmllint --noout /tmp/sm.xml; then
            echo "::warning::xmllint failed for sitemap.xml"
            [ "${STRICT_SEO}" = "true" ] && exit 1 || true
          fi

      - name: Fetch robots.txt as Googlebot (verbose)
        run: |
          set -x
          curl -v -A "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)" \
            -o /tmp/robots-gb.txt -w "\nHTTP:%{http_code}\n" https://www.gradeidea.cc/robots.txt || true
          echo "=== robots first 20 lines ==="
          sed -n '1,20p' /tmp/robots-gb.txt || true

      - name: Assert robots.txt exposes sitemap (tolerant)
        run: |
          set -x
          # Be flexible on capitalization, trailing slash, and host
          if grep -Eqi '^sitemap:\s*https?://(www\.)?gradeidea\.cc/sitemap\.xml/?$' /tmp/robots-gb.txt; then
            echo "robots.txt exposes sitemap correctly."
          else
            echo "::warning::robots.txt missing expected Sitemap line (or host mismatch)."
            echo "Tip: ensure exactly one line like: Sitemap: https://www.gradeidea.cc/sitemap.xml"
            [ "${STRICT_SEO}" = "true" ] && exit 1 || true
          fi

      - name: Sample sitemap URLs resolve 200 (tolerant)
        run: |
          set -x
          # Extract up to 25 <loc> URLs; tolerate redirects; only fail on 4xx/5xx in strict mode
          urls=$(grep -Eo '<loc>[^<]+' /tmp/sm.xml | sed 's/<loc>//' | head -n 25)
          if [ -z "$urls" ]; then
            echo "::warning::No <loc> URLs found in sitemap sample."
            [ "${STRICT_SEO}" = "true" ] && exit 1 || true
          fi
          err=0
          while read -r url; do
            [ -z "$url" ] && continue
            code=$(curl -s -o /dev/null -w "%{http_code}" -L "$url")
            echo "$code $url"
            if [ "$code" -ge 400 ]; then
              echo "::warning::Bad URL in sitemap: $url -> $code"
              err=1
            fi
          done <<< "$urls"
          if [ "$err" -ne 0 ] && [ "${STRICT_SEO}" = "true" ]; then
            exit 1
          fi

      - name: Verify IndexNow key file before submit
        run: |
          if [ -z "${INDEXNOW_KEY}" ]; then
            echo "INDEXNOW_KEY not set; will skip IndexNow in script."
            exit 0
          fi
          URL="https://www.gradeidea.cc/${INDEXNOW_KEY}.txt"
          echo "Checking ${URL} ..."
          code=$(curl -s -o /tmp/key.txt -w "%{http_code}" -L "$URL")
          echo "HTTP:$code"
          echo "Contents:"; cat /tmp/key.txt || true
          if [ "$code" != "200" ]; then
            echo "::warning::IndexNow key file not reachable (expect 200). The script will skip IndexNow."
          fi

      - name: Notify search engines that still listen (Bing/IndexNow)
        run: npm run ping-search
        env:
          INDEXNOW_KEY: ${{ secrets.INDEXNOW_KEY }}